{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check sync process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local configuration file found !!, no need to run the configuration (unless configuration has changed)\n"
     ]
    }
   ],
   "source": [
    "from scripts.conf_file_finding import try_find_conf_file\n",
    "try_find_conf_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-17 18:13:48,938][INFO]: DataJoint 0.14.4 connected to alvaros@datajoint00.pni.princeton.edu:3306\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datajoint as dj\n",
    "\n",
    "import u19_pipeline.ephys_pipeline as ephys_pipeline\n",
    "import u19_pipeline.utils.ephys_utils as ephys_utils\n",
    "import u19_pipeline.utils.ephys_fix_sync_code as ephys_fix_sync_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_query = \"recording_id > 512 and recording_id < 514\"\n",
    "recording = dj.create_virtual_module('recording', 'u19_recording')\n",
    "recording_keys = (recording.Recording & recording_query).fetch('recording_id', as_dict=True, order_by='recording_id')\n",
    "\n",
    "\n",
    "session_fields = ['subject_fullname', 'session_date', 'session_number']\n",
    "session_keys = (recording.Recording.BehaviorSession & recording_query).fetch(*session_fields, as_dict=True, order_by='recording_id')\n",
    "\n",
    "\n",
    "recording_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_ephys_fix_sync_code(iter_start_idx, iter_times_idx, behavior_time, nidq_sampling_rate, key):\n",
    "    iteration_dict = dict()\n",
    "    iteration_dict['iter_start_idx']  = list()\n",
    "    iteration_dict['iter_times_idx']  = list()\n",
    "    iteration_dict['trial_sync_stats'] = list()\n",
    "\n",
    "    for i in range(len(iter_start_idx)):\n",
    "\n",
    "        trial_stats_dict= {}\n",
    "        trial_stats_dict['num_trial'] = i+1\n",
    "\n",
    "        #print('fixing trial ',i)\n",
    "        behavior_time_vector = behavior_time[i].flatten()\n",
    "\n",
    "        #time_iteration = np.median(np.diff(behavior_time[0:5])\n",
    "\n",
    "        iter_times_idx[i] = iter_times_idx[i]+behavior_time_vector[1]\n",
    "        #iter_times_idx[i] = iter_times_idx[i]+behavior_time_vector[1]-(behavior_time_vector[2]-iter_times_idx[i][2])\n",
    "        #iter_times_idx[i] = iter_times_idx[i]+behavior_time_vector[1]\n",
    "        #synced_time_vector = np.insert(synced_time_vector, 1, behavior_time_vector[1])\n",
    "        #synced_time_vector[2:] = synced_time_vector[2:]+(behavior_time_vector[2]-synced_time_vector[2])\n",
    "        #synced_time_vector[0] = 0\n",
    "\n",
    "        synced_time_vector, shift_vec, median_vec = ephys_fix_sync_code.get_shift_vector(iter_times_idx[i],behavior_time_vector)\n",
    "\n",
    "        #if median_vec[1] < 0:\n",
    "        #    print('Trial # median more', i)\n",
    "        #    raise('Median less than 0')\n",
    "            \n",
    "        #    break\n",
    "\n",
    "        trial_stats_dict['max_shift'] = np.max(shift_vec)\n",
    "        trial_stats_dict['min_shift'] = np.min(shift_vec)\n",
    "        trial_stats_dict['median_diff'] = median_vec[1]\n",
    "        trial_stats_dict['min_diff'] = median_vec[0]\n",
    "        trial_stats_dict['max_diff'] = median_vec[2]\n",
    "\n",
    "        synced_time_vector,trial_stats_dict['borrow_step2'] =\\\n",
    "            ephys_fix_sync_code.fix_shifted_sync_vector(synced_time_vector, behavior_time_vector, shift_vec)\n",
    "\n",
    "        #synced_time_vector, trial_stats_dict['borrow_step3'] =\\\n",
    "        #    fix_sync_vector_greater(synced_time_vector, behavior_time_vector)\n",
    "        synced_time_vector,trial_stats_dict['borrow_step4'] =\\\n",
    "            ephys_fix_sync_code.complete_last_part_sync_vec(synced_time_vector, behavior_time_vector)\n",
    "\n",
    "        synced_iteration_vector =\\\n",
    "            ephys_fix_sync_code.fix_iter_vector(iter_start_idx[i],synced_time_vector, iter_times_idx[i], nidq_sampling_rate)\n",
    "        \n",
    "        \n",
    "\n",
    "        #print(synced_time_vector[0:5])\n",
    "        synced_time_vector = synced_time_vector+behavior_time_vector[1]\n",
    "        #print(synced_time_vector[0:5])\n",
    "        #print(behavior_time_vector[0:5])\n",
    "\n",
    "        diff_time = synced_time_vector - behavior_time_vector\n",
    "        trial_stats_dict['min_diff_all_time'] = diff_time.min()\n",
    "        trial_stats_dict['max_diff_all_time'] = diff_time.max()\n",
    "        \n",
    "\n",
    "        trial_stats_dict['num_iterations'] = synced_iteration_vector.shape[0] \n",
    "        trial_stats_dict = trial_stats_dict | key\n",
    "        iteration_dict['trial_sync_stats'].append(trial_stats_dict)\n",
    "\n",
    "\n",
    "        iteration_dict['iter_start_idx'].append(synced_iteration_vector.copy())\n",
    "        iteration_dict['iter_times_idx'].append(synced_time_vector.copy())\n",
    "\n",
    "    print('end fix sync code 1')\n",
    "\n",
    "    iteration_dict['iter_start_idx'] = np.asarray(iteration_dict['iter_start_idx'].copy(), dtype=object)\n",
    "    iteration_dict['iter_times_idx'] = np.asarray(iteration_dict['iter_times_idx'].copy(), dtype=object)\n",
    "\n",
    "    print('end fix sync code')\n",
    "\n",
    "    # Check # of trials and iterations match\n",
    "    trial_count_diff, trials_diff_iteration_big, trials_diff_iteration_small = ephys_utils.assert_iteration_samples_count(iteration_dict['iter_start_idx'], behavior_time)\n",
    "\n",
    "    print('after assert_iteration_samples_count fix sync code')\n",
    "\n",
    "    if trial_count_diff != 0:\n",
    "        print('trial_count_diff', trial_count_diff)\n",
    "    if len(trials_diff_iteration_big) > 0:\n",
    "        print('trials_diff_iteration_big', trials_diff_iteration_big)\n",
    "    if len(trials_diff_iteration_small) > 0:\n",
    "        print('trials_diff_iteration_small', trials_diff_iteration_small)\n",
    "\n",
    "\n",
    "    status = ephys_utils.evaluate_sync_process(trial_count_diff, trials_diff_iteration_big, trials_diff_iteration_small,  behavior_time.shape[0])\n",
    "\n",
    "    print('after evaluate_sync_process fix sync code')\n",
    "\n",
    "    for i in range(len(iteration_dict['iter_start_idx'])):\n",
    "        synced_time_vector = iteration_dict['iter_times_idx'][i]\n",
    "        behavior_time_vector = behavior_time[i].flatten()\n",
    "\n",
    "        status = ephys_fix_sync_code.sync_evaluation_process2(synced_time_vector, behavior_time_vector)\n",
    "        if status == -1:\n",
    "            break\n",
    "\n",
    "    print('after sync_evaluation_process2', status)\n",
    "\n",
    "    if status == 1:\n",
    "        iteration_dict['trial_start_idx'] = ephys_utils.get_index_trial_vector_from_iteration(iteration_dict['iter_start_idx'])\n",
    "\n",
    "\n",
    "    return status, iteration_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_regular_sync(key, **kwargs):\n",
    "\n",
    "    ephys_session_fullpath = ephys_pipeline.get_full_session_directory(key)\n",
    "\n",
    "    # Get behavior key\n",
    "    behavior_key = (recording.Recording.BehaviorSession & key).fetch1()\n",
    "    behavior_key.pop('recording_id')\n",
    "\n",
    "    if 'testuser' in behavior_key['subject_fullname']:\n",
    "        return\n",
    "\n",
    "    # If a specific block is requested, add that to our behavior_key. It should be an int referring to virmen block number.\n",
    "    # This is useful for sessions in which the nidaq stream was interrupted due to restarting virmen\n",
    "    if 'block' in kwargs:\n",
    "        print('block: ', kwargs['block'])\n",
    "        behavior_key['block'] = kwargs['block']\n",
    "\n",
    "    print(behavior_key)\n",
    "\n",
    "    # And get the datajoint record\n",
    "    #behavior = dj.create_virtual_module('behavior', 'u19_behavior')\n",
    "    #thissession = behavior.TowersBlock().Trial() & behavior_key\n",
    "    #behavior_time, iterstart = thissession.fetch('trial_time', 'vi_start')\n",
    "\n",
    "    behavior_time,_ = ephys_utils.get_real_behavior_time(behavior_key)\n",
    "\n",
    "    print('after reading behavior data')\n",
    "\n",
    "    # 1: load meta data, and the content of the NIDAQ file. Its content is digital.\n",
    "    nidq_meta, nidq_sampling_rate = ephys_utils.read_nidq_meta_samp_rate(ephys_session_fullpath)\n",
    "\n",
    "    trial_pulse_signal, iteration_pulse_signal = ephys_utils.load_trial_iteration_signals(ephys_session_fullpath, nidq_meta)\n",
    "\n",
    "    print('after reading spikeglx data')\n",
    "\n",
    "    # Synchronize between pulses and get iteration # vector for each sample\n",
    "    recent_recording = behavior_key['session_date'] > datetime.date(2021,6,1) # Everything past June 1 2021\n",
    "    if recent_recording:\n",
    "        # New synchronization method: digital_array[1,2] contain pulses for trial and frame number.\n",
    "        mode=None\n",
    "        iteration_dict = ephys_utils.get_iteration_sample_vector_from_digital_lines_pulses(trial_pulse_signal, iteration_pulse_signal, nidq_sampling_rate, behavior_time.shape[0], behavior_time, mode)\n",
    "    else:\n",
    "        # Old synchronization: digital_array[0:7] contain a digital word that counts the virmen frames.\n",
    "        raise ValueError('Old sessions < 2022 not suported anymore')\n",
    "        #iteration_dict = ephys_utils.get_iteration_sample_vector_from_digital_lines_word(digital_array, behavior_time, iterstart)\n",
    "\n",
    "    # Check # of trials (from database record of behavior in `behavior_time`) and iterations (extracted from NIDAQ in `iter_start_idx`) match\n",
    "    trial_count_diff, trials_diff_iteration_big, trials_diff_iteration_small = ephys_utils.assert_iteration_samples_count(iteration_dict['iter_start_idx'], behavior_time)\n",
    "\n",
    "    print('metrics to evaluate...')\n",
    "    print(trial_count_diff, trials_diff_iteration_big, trials_diff_iteration_small, behavior_time.shape[0])\n",
    "\n",
    "    status = ephys_utils.evaluate_sync_process(trial_count_diff, trials_diff_iteration_big, trials_diff_iteration_small, behavior_time.shape[0])\n",
    "\n",
    "    if status == 1:\n",
    "        iteration_dict['trial_start_idx'] = ephys_utils.get_index_trial_vector_from_iteration(iteration_dict['iter_start_idx'])\n",
    "\n",
    "    #Failed sync by a lot, error\n",
    "    status_regular = 1\n",
    "    status_fix = 0\n",
    "    if status < 1:\n",
    "        status_regular = 0\n",
    "        print('Regular ephys sync failed')\n",
    "    \n",
    "    try:\n",
    "        status_fix, iteration_dict2 = main_ephys_fix_sync_code(iteration_dict['iter_start_idx'], iteration_dict['iter_times_idx'], behavior_time, nidq_sampling_rate, key)\n",
    "    except:\n",
    "        status_fix = 0\n",
    "        iteration_dict2 = {}\n",
    "\n",
    "    return status_fix, iteration_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(ephys_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_session = 0\n",
    "for idx_session in range(len(recording_keys)):\n",
    "\n",
    "    recording_key = recording_keys[idx_session]\n",
    "    session_key = session_keys[idx_session]\n",
    "\n",
    "    status_fix, iteration_dict2 = main_regular_sync(recording_key)\n",
    "    if status_fix == 0:\n",
    "        continue\n",
    "\n",
    "    print('session_key', session_key)\n",
    "\n",
    "    for i in range(len(iteration_dict2['trial_sync_stats'])):\n",
    "        iteration_dict2['trial_sync_stats'][i] = iteration_dict2['trial_sync_stats'][i] | session_key\n",
    "\n",
    "    print('status_fix', status_fix)\n",
    "    print('num_session', num_session)\n",
    "    \n",
    "    if num_session == 0:\n",
    "        trial_sync_stats_df = pd.DataFrame(iteration_dict2['trial_sync_stats'])\n",
    "    else:\n",
    "        trial_sync_stats_df = pd.concat([trial_sync_stats_df, pd.DataFrame(iteration_dict2['trial_sync_stats'])], axis=0)\n",
    "\n",
    "    num_session += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_borrowed_iter(borrow_list):\n",
    "    num_borrow = 0\n",
    "    for i in range(len(borrow_list)):\n",
    "        num_borrow = num_borrow+ borrow_list[i][1] - borrow_list[i][0] + 1\n",
    "\n",
    "    return num_borrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trial_sync_stats_df['min_shift_abs'] = trial_sync_stats_df['min_shift'].abs()\n",
    "trial_sync_stats_df['shift'] = trial_sync_stats_df[['max_shift', 'min_shift_abs']].max(axis=1)\n",
    "\n",
    "trial_sync_stats_df.loc[trial_sync_stats_df['shift']==trial_sync_stats_df['min_shift_abs'], 'shift'] = trial_sync_stats_df.loc[trial_sync_stats_df['shift']==trial_sync_stats_df['min_shift_abs'], 'shift']*-1\n",
    "\n",
    "trial_sync_stats_df['num_borrow_step2'] = trial_sync_stats_df['borrow_step2'].apply(count_borrowed_iter)\n",
    "#trial_sync_stats_df['num_borrow_step3'] = trial_sync_stats_df['borrow_step3'].apply(count_borrowed_iter)\n",
    "trial_sync_stats_df['num_borrow_step4'] = trial_sync_stats_df['borrow_step4'].apply(count_borrowed_iter)\n",
    "\n",
    "\n",
    "#trial_sync_stats_df['total_borrow'] = trial_sync_stats_df['num_borrow_step2'] + trial_sync_stats_df['num_borrow_step3'] + trial_sync_stats_df['num_borrow_step4']  \n",
    "\n",
    "trial_sync_stats_df['total_borrow'] = trial_sync_stats_df['num_borrow_step4'] + trial_sync_stats_df['num_borrow_step2']\n",
    "\n",
    "trial_sync_stats_df['percentage_borrow'] = trial_sync_stats_df['total_borrow']*100 / trial_sync_stats_df['num_iterations']\n",
    "\n",
    "\n",
    "trial_sync_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_sync_stats_df = trial_sync_stats_df.sort_values(by='max_diff_all_time', ascending=False)\n",
    "trial_sync_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_sync_stats_df.loc[trial_sync_stats_df['median_diff'] < -0.0001, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_sync_stats_df['min_shift_abs'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "shift_stats = trial_sync_stats_df['median_diff'].copy()\n",
    "num_0_shifts = (shift_stats == 0).sum()\n",
    "\n",
    "num_shifts = shift_stats[shift_stats != 0]\n",
    "\n",
    "\n",
    "plt.hist(num_shifts,bins=61)\n",
    "\n",
    "\n",
    "plt.xlabel('Time(s)')\n",
    "plt.ylabel('# Trials')\n",
    "plt.title('Median diff NIDAQ - ViRMEn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trial_sync_stats_df['min_shift_abs'] = trial_sync_stats_df['min_shift'].abs()\n",
    "trial_sync_stats_df['shift'] = trial_sync_stats_df[['max_shift', 'min_shift_abs']].max(axis=1)\n",
    "\n",
    "trial_sync_stats_df.loc[trial_sync_stats_df['shift']==trial_sync_stats_df['min_shift_abs'], 'shift'] = trial_sync_stats_df.loc[trial_sync_stats_df['shift']==trial_sync_stats_df['min_shift_abs'], 'shift']*-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "shift_stats = trial_sync_stats_df['shift'].copy()\n",
    "num_0_shifts = (shift_stats == 0).sum()\n",
    "\n",
    "num_shifts = shift_stats[shift_stats != 0]\n",
    "\n",
    "\n",
    "plt.hist(num_shifts)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlabel('# Shift iterations')\n",
    "plt.ylabel('# Trials')\n",
    "plt.title('\"Max\" shift in trial to preserve median: '+ str(num_0_shifts)+ ' trials without shift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "\n",
    "\n",
    "plt.hist(trial_sync_stats_df['percentage_borrow'])\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlabel('% Trial')\n",
    "plt.ylabel('# Trials')\n",
    "plt.title('Trial NIDAQ iterations borrowed from ViRMEn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(trial_sync_stats_df['percentage_borrow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "u19-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
